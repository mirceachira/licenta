{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwards optimization notebook\n",
    "\n",
    "By forward optimization here I mean optimization that only tunes existing parameters.\n",
    "AKA finding the optimal value for any given parameter the strategy has so that it yields better results.\n",
    "\n",
    "This notebook aims to create an interface json which can later be easily read for the optimal parameters for a given timeframe (start to date and period before to date)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil import rrule\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# from matplotlib import pyplot\n",
    "# import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "\n",
    "TIMEFRAME = \"daily\"\n",
    "# TIMEFRAME = 'weekly'\n",
    "\n",
    "# FRAMEWORK = 'dask'\n",
    "FRAMEWORK = \"pandas\"\n",
    "\n",
    "FIRST_DATE = datetime.datetime(2000, 1, 1)\n",
    "LAST_DATE = datetime.datetime(2020, 12, 31)\n",
    "\n",
    "FORWARD_OPT_RESULTS_JSON = f\"results/{TIMEFRAME}/forward_opt_results.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(the_df):\n",
    "    print(f\"There are {len(the_df)} rows in the dataframe/series\")\n",
    "    try:\n",
    "        res = the_df.sample(frac=5)\n",
    "    except ValueError:\n",
    "        res = the_df.sample(3)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(key, results_for_key):\n",
    "    with open(FORWARD_OPT_RESULTS_JSON, \"r\") as f:\n",
    "        results_dict = json.loads(f.read())\n",
    "\n",
    "    results_dict[key] = results_for_key\n",
    "\n",
    "    with open(FORWARD_OPT_RESULTS_JSON, \"w\") as f:\n",
    "        f.write(json.dumps(results_dict))\n",
    "\n",
    "\n",
    "# save_results('a', {1:2,3:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_entry(start_date, end_date):\n",
    "    return (\n",
    "        f\"{start_date.strftime('%y-%m')}-to-{end_date.strftime('%y-%m')}\",\n",
    "        start_date,\n",
    "        end_date,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_date_ranges():\n",
    "    resulting_dict = {}\n",
    "    for end_date in rrule.rrule(rrule.MONTHLY, dtstart=FIRST_DATE, until=LAST_DATE):\n",
    "        resulting_dict[end_date.strftime(\"%y-%m\")] = {\n",
    "            #             '1-month': get_pair_entry(end_date + relativedelta(months=-1), end_date),\n",
    "            #             '3-month': get_pair_entry(end_date + relativedelta(months=-3), end_date),\n",
    "            \"6-month\": get_pair_entry(end_date + relativedelta(months=-6), end_date),\n",
    "            \"12-month\": get_pair_entry(end_date + relativedelta(months=-12), end_date),\n",
    "            \"max\": get_pair_entry(datetime.datetime(1998, 1, 1), end_date),\n",
    "        }\n",
    "\n",
    "    return resulting_dict\n",
    "\n",
    "\n",
    "def get_parsed_date_ranges():\n",
    "    with open(FORWARD_OPT_RESULTS_JSON, \"r\") as f:\n",
    "        results_dict = json.loads(f.read())\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "# for k,v in generate_date_ranges().items():\n",
    "#     print(k)\n",
    "#     print(v)\n",
    "# #     range_name, key, start_date, end_date = v\n",
    "# #     print(range_name, key, start_date, end_date)\n",
    "#     raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TIMEFRAME == \"daily\":\n",
    "    path = \"dataset/daily/\"\n",
    "    column_names = [\n",
    "        \"uid\",\n",
    "        \"ticker\",\n",
    "        \"date\",\n",
    "        \"price_open\",\n",
    "        \"maperiod\",\n",
    "        \"rsi_open_period\",\n",
    "        \"adx8\",\n",
    "        \"adx16\",\n",
    "        \"adx32\",\n",
    "        \"ppo8\",\n",
    "        \"ppo16\",\n",
    "        \"ppo32\",\n",
    "        \"stochastic8\",\n",
    "        \"stochastic16\",\n",
    "        \"stochastic32\",\n",
    "        \"price_sell\",\n",
    "        \"days_ago_close_period\",\n",
    "        \"rsi_close_period\",\n",
    "    ]\n",
    "elif TIMEFRAME == \"weekly\":\n",
    "    path = \"dataset/weekly/\"\n",
    "    column_names = [\n",
    "        \"uid\",\n",
    "        \"ticker\",\n",
    "        \"date\",\n",
    "        \"price_open\",\n",
    "        \"maperiod\",\n",
    "        \"rsi_open_period\",\n",
    "        \"adx3\",\n",
    "        \"adx6\",\n",
    "        \"adx9\",\n",
    "        \"ppo3\",\n",
    "        \"ppo6\",\n",
    "        \"ppo9\",\n",
    "        \"stochastic3\",\n",
    "        \"stochastic6\",\n",
    "        \"stochastic9\",\n",
    "        \"price_sell\",\n",
    "        \"days_ago_close_period\",\n",
    "        \"rsi_close_period\",\n",
    "    ]\n",
    "\n",
    "if FRAMEWORK == \"pandas\":\n",
    "    d = pd\n",
    "    f = f\"{path}/all_results.csv\"\n",
    "elif FRAMEWORK == \"dask\":\n",
    "    d = dd\n",
    "    f = f\"{path}/*.csv\"\n",
    "\n",
    "df = d.read_csv(\n",
    "    f,\n",
    "    names=column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FRAMEWORK == \"dask\":\n",
    "    print(df.shape[0].compute())\n",
    "else:\n",
    "    print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the change percentage\n",
    "And drop the price_sell and price_open columns because they are no longer used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the percentage change for the price\n",
    "df[\"perc_change\"] = (df[\"price_sell\"] - df[\"price_open\"]) / df[\"price_open\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prices can now be dropped since I won't need them anymore\n",
    "df = df.drop([\"price_sell\", \"price_open\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_optimal_func(tmp_df_groupby):\n",
    "    tmp_series = tmp_df_groupby[\"perc_change\"].mean()\n",
    "\n",
    "    if FRAMEWORK == \"dask\":\n",
    "        tmp_series = tmp_series.compute()\n",
    "\n",
    "    return tmp_series.sort_values(ascending=False).index[0]\n",
    "\n",
    "\n",
    "def order_optimal_func(tmp_df_groupby):\n",
    "    def outcome_computation(x):\n",
    "        l = []\n",
    "        for _, perc_change in x.sort_values([\"date\"])[\"perc_change\"].iteritems():\n",
    "            l.append(perc_change)\n",
    "\n",
    "        results = []\n",
    "        for i in range(len(l)):\n",
    "            res = 1\n",
    "            for j in range(i, len(l)):\n",
    "                res += (res * l[j]) / 100\n",
    "            results.append(res)\n",
    "\n",
    "        return sum(results) / len(results)\n",
    "\n",
    "    if FRAMEWORK == \"pandas\":\n",
    "        outcome_series = tmp_df_groupby.apply(outcome_computation)\n",
    "        res = outcome_series.sort_values(ascending=False).index[0]\n",
    "    else:\n",
    "        outcome_series = tmp_df_groupby.apply(outcome_computation, meta=(\"float\"))\n",
    "        res = outcome_series.compute().sort_values(ascending=False).index[0]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_optimal_params_using_func(df, func):\n",
    "    optimal_days_ago = int(func(df.groupby([\"days_ago_close_period\"])))\n",
    "    df = df[df[\"days_ago_close_period\"] == optimal_days_ago]\n",
    "\n",
    "    optimal_rsi_open = int(func(df.groupby([\"rsi_open_period\"])))\n",
    "    df = df[df[\"rsi_open_period\"] == optimal_rsi_open]\n",
    "\n",
    "    optimal_maperiod = int(func(df.groupby([\"maperiod\"])))\n",
    "    df = df[df[\"maperiod\"] == optimal_maperiod]\n",
    "\n",
    "    result = {\n",
    "        \"days_ago_close_period\": optimal_days_ago,\n",
    "        \"rsi_open_period\": optimal_rsi_open,\n",
    "        \"maperiod\": optimal_maperiod,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_optimal_results(df):\n",
    "    return {\n",
    "        \"mean\": compute_optimal_params_using_func(df, mean_optimal_func),\n",
    "        \"order\": compute_optimal_params_using_func(df, order_optimal_func),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_computation(x):\n",
    "    l = []\n",
    "\n",
    "    for perc_change in x.sort_values([\"date\"])[\"perc_change\"].values:\n",
    "        l.append(perc_change)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(l)):\n",
    "        res = 1\n",
    "        for j in range(i, len(l)):\n",
    "            res += (res * l[j]) / 100\n",
    "        results.append(res)\n",
    "\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_dates(df, start_date, end_date):\n",
    "    return df[\n",
    "        (df[\"date\"] >= start_date.strftime(\"%Y-%m-%d\"))\n",
    "        & (df[\"date\"] <= end_date.strftime(\"%Y-%m-%d\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGY_OUT_OF_THE_BOX_KWARGS = (\n",
    "    {\"maperiod\": 200, \"rsi_open_period\": 10, \"days_ago_close_period\": 10}\n",
    "    if TIMEFRAME == \"daily\"\n",
    "    else {\"maperiod\": 40, \"rsi_open_period\": 2, \"days_ago_close_period\": 2}\n",
    ")\n",
    "DEFAULT_STRATEGY_KWARGS = {\n",
    "    \"mean\": STRATEGY_OUT_OF_THE_BOX_KWARGS,\n",
    "    \"order\": STRATEGY_OUT_OF_THE_BOX_KWARGS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date_ranges = generate_date_ranges()\n",
    "parsed_date_ranges = get_parsed_date_ranges()\n",
    "unparsed_date_ranges = {\n",
    "    k: v for k, v in all_date_ranges.items() if k not in parsed_date_ranges\n",
    "}\n",
    "# TODO: check 01-11 adn 02-12 (or up to '03-02'?) for daily timeframe\n",
    "try:\n",
    "    print(list(unparsed_date_ranges.items())[0])\n",
    "except IndexError:\n",
    "    print(\"All ranges have been parsed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tqdm.tqdm(total=len(unparsed_date_ranges)) as pbar:\n",
    "    # Simple caching mechanism to speed things up for a lot of computations\n",
    "    PREVIOUS_SIZE = None\n",
    "    PREVIOUS_RES = None\n",
    "\n",
    "    for date_value, date_ranges in unparsed_date_ranges.items():\n",
    "        optimal_results = {}\n",
    "\n",
    "        def optimize_range(df, range_name, default_if_empty):\n",
    "            range_values = date_ranges[range_name]\n",
    "            _, start_date, end_date = range_values\n",
    "\n",
    "            filtered_df = filter_df_by_dates(df, start_date, end_date)\n",
    "            size = (\n",
    "                filtered_df.shape[0]\n",
    "                if FRAMEWORK == \"pandas\"\n",
    "                else filtered_df.shape[0].compute()\n",
    "            )\n",
    "\n",
    "            if size == globals()[\"PREVIOUS_SIZE\"]:\n",
    "                print(f\"Using chache for {range_name} - {start_date} to {end_date}\")\n",
    "                return globals()[\"PREVIOUS_RES\"]\n",
    "\n",
    "            if size < 100:\n",
    "                print(\n",
    "                    f\"Empty or too small df from (size: {size}) {start_date} to {end_date}\"\n",
    "                )\n",
    "                res = default_if_empty\n",
    "            else:\n",
    "                print(f\"Parsing {size} lines from {start_date} to {end_date}\")\n",
    "                res = compute_optimal_results(filtered_df)\n",
    "\n",
    "            globals()[\"PREVIOUS_SIZE\"] = size\n",
    "            globals()[\"PREVIOUS_RES\"] = res\n",
    "\n",
    "            return res\n",
    "\n",
    "        optimal_results[\"12-month\"] = optimize_range(df, \"12-month\", None)\n",
    "        optimal_results[\"6-month\"] = optimize_range(\n",
    "            df, \"6-month\", optimal_results[\"12-month\"]\n",
    "        )\n",
    "\n",
    "        print(date_value)\n",
    "        print(optimal_results)\n",
    "        save_results(date_value, optimal_results)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
